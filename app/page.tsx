"use client";

export const dynamic = "force-dynamic";
export const revalidate = false;

import type React from "react"

import { useState, useRef, useEffect, useCallback } from "react"
import { Mic, Upload } from "lucide-react"
import { Button } from "@/components/ui/button"
import { Badge } from "@/components/ui/badge"
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card"
import { Progress } from "@/components/ui/progress"
import AudioAnalysis from "./components/audio-analysis"
import SonarView from "./components/sonar-view"
import AudioSettings from "./components/audio-settings"
import LiveVisualization from "./components/live-visualization"

// ... rest of your existing code unchanged ...

interface AudioData {
  blob: Blob
  url: string
  name: string
  duration: number
  analysisResults?: any
}

export default function AudioForensicDetector() {
  const [activeTab, setActiveTab] = useState("Record")
  const [isRecording, setIsRecording] = useState(false)
  const [audioData, setAudioData] = useState<AudioData | null>(null)
  const [recordingTime, setRecordingTime] = useState(0)
  const [isPlaying, setIsPlaying] = useState(false)
  const [analysisProgress, setAnalysisProgress] = useState(0)
  const [isAnalyzing, setIsAnalyzing] = useState(false)
  const [recordingStatus, setRecordingStatus] = useState<string>("")

  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const audioRef = useRef<HTMLAudioElement | null>(null)
  const recordingIntervalRef = useRef<NodeJS.Timeout | null>(null)
  const streamRef = useRef<MediaStream | null>(null)

  const tabs = ["Record", "Upload", "Analyze", "Sonar View", "About Us", "Settings"]

  useEffect(() => {
    return () => {
      if (recordingIntervalRef.current) {
        clearInterval(recordingIntervalRef.current)
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop())
      }
    }
  }, [])

  const startRecording = async () => {
    try {
      setRecordingStatus("Requesting microphone access...")

      // Check if we're in a secure context (HTTPS or localhost)
      if (!window.isSecureContext) {
        setRecordingStatus("Error: HTTPS required for microphone access")
        alert("Microphone access requires HTTPS or localhost. Please use a secure connection.")
        return
      }

      // Check if getUserMedia is supported
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        setRecordingStatus("Error: Browser doesn't support audio recording")
        alert(
          "Your browser doesn't support audio recording. Please use a modern browser like Chrome, Firefox, or Safari.",
        )
        return
      }

      setRecordingStatus("Accessing microphone...")

      // Request microphone permission with optimal constraints
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: { ideal: 44100 },
          channelCount: { ideal: 1 },
        },
      })

      streamRef.current = stream
      setRecordingStatus("Microphone access granted")

      // Find the best supported MIME type
      const supportedTypes = ["audio/webm;codecs=opus", "audio/webm", "audio/mp4", "audio/ogg;codecs=opus", "audio/wav"]

      let mimeType = ""
      for (const type of supportedTypes) {
        if (MediaRecorder.isTypeSupported(type)) {
          mimeType = type
          break
        }
      }

      if (!mimeType) {
        console.warn("No supported MIME type found, using default")
      }

      setRecordingStatus("Initializing recorder...")

      // Create MediaRecorder with optimal settings
      const options: MediaRecorderOptions = {
        audioBitsPerSecond: 128000,
      }

      if (mimeType) {
        options.mimeType = mimeType
      }

      mediaRecorderRef.current = new MediaRecorder(stream, options)
      audioChunksRef.current = []

      // Set up event handlers
      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data)
          console.log(`Audio chunk received: ${event.data.size} bytes`)
        }
      }

      mediaRecorderRef.current.onstop = async () => {
        setRecordingStatus("Processing recording...")
        console.log(`Total chunks collected: ${audioChunksRef.current.length}`)

        if (audioChunksRef.current.length === 0) {
          setRecordingStatus("Error: No audio data recorded")
          alert("No audio data was recorded. Please try again.")
          return
        }

        // Create audio blob
        const audioBlob = new Blob(audioChunksRef.current, {
          type: mimeType || "audio/wav",
        })

        console.log(`Audio blob created: ${audioBlob.size} bytes, type: ${audioBlob.type}`)

        if (audioBlob.size === 0) {
          setRecordingStatus("Error: Empty recording")
          alert("Recording is empty. Please try again.")
          return
        }

        const audioUrl = URL.createObjectURL(audioBlob)

        // Determine file extension
        let extension = ".wav"
        if (mimeType.includes("webm")) extension = ".webm"
        else if (mimeType.includes("mp4")) extension = ".mp4"
        else if (mimeType.includes("ogg")) extension = ".ogg"

        const newAudioData: AudioData = {
          blob: audioBlob,
          url: audioUrl,
          name: `Recording_${new Date().toISOString().slice(0, 19).replace(/:/g, "-")}${extension}`,
          duration: recordingTime,
        }

        setAudioData(newAudioData)
        setRecordingStatus("Recording saved successfully!")

        // Stop all tracks to release the microphone
        if (streamRef.current) {
          streamRef.current.getTracks().forEach((track) => track.stop())
          streamRef.current = null
        }

        // Auto-analyze the recorded audio
        setTimeout(() => {
          analyzeRecordedAudio(newAudioData)
        }, 1000)
      }

      mediaRecorderRef.current.onerror = (event) => {
        console.error("MediaRecorder error:", event)
        setRecordingStatus("Recording error occurred")
        alert("Recording error occurred. Please try again.")
        setIsRecording(false)
        if (recordingIntervalRef.current) {
          clearInterval(recordingIntervalRef.current)
        }
      }

      mediaRecorderRef.current.onstart = () => {
        setRecordingStatus("Recording in progress...")
        console.log("Recording started successfully")
      }

      // Start recording with data collection every 1000ms
      mediaRecorderRef.current.start(1000)
      setIsRecording(true)
      setRecordingTime(0)

      // Start timer
      recordingIntervalRef.current = setInterval(() => {
        setRecordingTime((prev) => prev + 1)
      }, 1000)

      console.log("Recording started with MIME type:", mimeType)
    } catch (error: any) {
      console.error("Error accessing microphone:", error)
      setRecordingStatus(`Error: ${error.message}`)

      // Provide specific error messages
      if (error.name === "NotAllowedError" || error.name === "PermissionDeniedError") {
        alert("Microphone access denied. Please allow microphone permissions and try again.")
      } else if (error.name === "NotFoundError" || error.name === "DevicesNotFoundError") {
        alert("No microphone found. Please connect a microphone and try again.")
      } else if (error.name === "NotReadableError" || error.name === "TrackStartError") {
        alert(
          "Microphone is already in use by another application. Please close other apps using the microphone and try again.",
        )
      } else if (error.name === "OverconstrainedError" || error.name === "ConstraintNotSatisfiedError") {
        // Retry with basic constraints
        try {
          setRecordingStatus("Retrying with basic settings...")
          const basicStream = await navigator.mediaDevices.getUserMedia({ audio: true })
          streamRef.current = basicStream

          mediaRecorderRef.current = new MediaRecorder(basicStream)
          audioChunksRef.current = []

          mediaRecorderRef.current.ondataavailable = (event) => {
            if (event.data.size > 0) {
              audioChunksRef.current.push(event.data)
            }
          }

          mediaRecorderRef.current.onstop = async () => {
            const audioBlob = new Blob(audioChunksRef.current, { type: "audio/wav" })
            const audioUrl = URL.createObjectURL(audioBlob)

            const newAudioData: AudioData = {
              blob: audioBlob,
              url: audioUrl,
              name: `Recording_${new Date().toISOString().slice(0, 19).replace(/:/g, "-")}.wav`,
              duration: recordingTime,
            }

            setAudioData(newAudioData)
            setRecordingStatus("Recording saved with basic settings")

            basicStream.getTracks().forEach((track) => track.stop())

            // Auto-analyze
            setTimeout(() => {
              analyzeRecordedAudio(newAudioData)
            }, 1000)
          }

          mediaRecorderRef.current.start(1000)
          setIsRecording(true)
          setRecordingTime(0)

          recordingIntervalRef.current = setInterval(() => {
            setRecordingTime((prev) => prev + 1)
          }, 1000)

          setRecordingStatus("Recording with basic settings...")
        } catch (retryError) {
          console.error("Retry failed:", retryError)
          setRecordingStatus("Unable to access microphone")
          alert("Unable to access microphone. Please check your browser settings and permissions.")
        }
      } else {
        alert(
          `Microphone error: ${error.message || "Unknown error occurred"}. Please check your browser settings and try again.`,
        )
      }
    }
  }

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      setRecordingStatus("Stopping recording...")
      mediaRecorderRef.current.stop()
      setIsRecording(false)

      if (recordingIntervalRef.current) {
        clearInterval(recordingIntervalRef.current)
      }
    }
  }

  const handleFileUpload = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0]
    if (file) {
      const audioUrl = URL.createObjectURL(file)
      const newAudioData: AudioData = {
        blob: file,
        url: audioUrl,
        name: file.name,
        duration: 0, // Will be updated when audio loads
      }
      setAudioData(newAudioData)

      // Auto-analyze uploaded file
      setTimeout(() => {
        analyzeRecordedAudio(newAudioData)
      }, 1000)
    }
  }

  const analyzeRecordedAudio = useCallback(async (audioToAnalyze: AudioData) => {
    if (!audioToAnalyze) return

    setIsAnalyzing(true)
    setAnalysisProgress(0)

    // Simulate realistic analysis progress
    const progressInterval = setInterval(() => {
      setAnalysisProgress((prev) => {
        if (prev >= 100) {
          clearInterval(progressInterval)
          return 100
        }
        return prev + 8
      })
    }, 400)

    try {
      // Create more realistic analysis results based on audio duration
      const duration = audioToAnalyze.duration || 5
      const numEvents = Math.max(3, Math.floor(duration * 1.5)) // More events for longer audio

      // Generate realistic sound events
      const soundTypes = [
        "Voice",
        "Background",
        "Ambient",
        "Noise",
        "Echo",
        "Music",
        "Percussion",
        "Wind",
        "Electronic",
      ]
      const soundEvents = []

      for (let i = 0; i < numEvents; i++) {
        const time = (i / (numEvents - 1)) * duration
        const baseFreq = 200 + Math.random() * 2000
        const amplitude = 0.3 + Math.random() * 0.7

        soundEvents.push({
          time: Number.parseFloat(time.toFixed(2)),
          frequency: Number.parseFloat(baseFreq.toFixed(1)),
          amplitude: Number.parseFloat(amplitude.toFixed(3)),
          type: soundTypes[Math.floor(Math.random() * soundTypes.length)],
          decibels: Number.parseFloat((20 * Math.log10(amplitude)).toFixed(1)),
        })
      }

      // Sort by amplitude (loudest first)
      soundEvents.sort((a, b) => b.amplitude - a.amplitude)

      // Generate frequency spectrum
      const frequencySpectrum = Array.from({ length: 100 }, (_, i) => ({
        frequency: i * 220,
        magnitude: Math.random() * 0.8 + 0.1,
      }))

      const analysisResults = {
        duration: duration,
        sampleRate: 44100,
        averageRMS: 0.0234 + Math.random() * 0.02,
        detectedSounds: numEvents,
        dominantFrequency: soundEvents[0]?.frequency || 440,
        maxDecibels: Math.max(...soundEvents.map((e) => e.decibels)),
        soundEvents: soundEvents,
        frequencySpectrum: frequencySpectrum,
        analysisComplete: true,
        timestamp: new Date().toISOString(),
      }

      // Wait for analysis to complete
      setTimeout(() => {
        setAudioData((prevData) => {
          if (prevData && prevData.url === audioToAnalyze.url) {
            return { ...prevData, analysisResults }
          }
          return prevData
        })

        setIsAnalyzing(false)
        clearInterval(progressInterval)
        setAnalysisProgress(100)

        // Auto-switch to Analyze tab to show results
        setActiveTab("Analyze")
      }, 3000)
    } catch (error) {
      console.error("Analysis error:", error)
      setIsAnalyzing(false)
      clearInterval(progressInterval)
      alert("Analysis failed. Please try again.")
    }
  }, [])

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60)
    const secs = seconds % 60
    return `${mins.toString().padStart(2, "0")}:${secs.toString().padStart(2, "0")}`
  }

  const checkMicrophoneSupport = () => {
    const isSupported = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia)
    const isSecure = window.isSecureContext
    const hasMediaRecorder = typeof MediaRecorder !== "undefined"

    return {
      isSupported,
      isSecure,
      hasMediaRecorder,
      canRecord: isSupported && isSecure && hasMediaRecorder,
    }
  }

  return (
    <div className="min-h-screen bg-gray-50">
      {/* Header */}
      <div className="text-center py-8 px-4">
        <h1 className="text-4xl font-bold text-purple-600 mb-2">Audio Forensic Detector</h1>
        <p className="text-purple-500 text-lg mb-4">Advanced Audio Analysis & Instrument Detection System</p>
        <Badge variant="secondary" className="bg-orange-100 text-orange-800 border-orange-200">
          Local Mode
        </Badge>
      </div>

      {/* Navigation Tabs */}
      <div className="max-w-6xl mx-auto px-4 mb-8">
        <div className="flex flex-wrap justify-center gap-2">
          {tabs.map((tab) => (
            <button
              key={tab}
              onClick={() => setActiveTab(tab)}
              className={`px-6 py-3 rounded-lg font-medium transition-all ${activeTab === tab
                ? "bg-purple-600 text-white shadow-lg"
                : "bg-white text-gray-600 hover:bg-gray-100 border border-gray-200"
                }`}
            >
              {tab}
            </button>
          ))}
        </div>
      </div>

      {/* Main Content */}
      <div className="max-w-6xl mx-auto px-4">
        <div className="bg-white rounded-lg shadow-sm border border-gray-200 p-8">
          {activeTab === "Record" && (
            <div className="text-center">
              <h2 className="text-2xl font-bold text-purple-600 mb-4">Audio Recording</h2>
              <p className="text-gray-600 mb-8 max-w-2xl mx-auto">
                Record live audio for forensic analysis with instrument detection - data flows to all tabs
              </p>

              {/* Browser Compatibility Check */}
              {(() => {
                const support = checkMicrophoneSupport()
                if (!support.canRecord) {
                  return (
                    <div className="mb-6 p-4 bg-yellow-50 border border-yellow-200 rounded-lg max-w-2xl mx-auto">
                      <h3 className="font-semibold text-yellow-800 mb-2">Recording Requirements</h3>
                      <ul className="text-sm text-yellow-700 space-y-1">
                        {!support.isSecure && <li>â€¢ HTTPS connection required for microphone access</li>}
                        {!support.isSupported && <li>â€¢ Browser doesn't support audio recording</li>}
                        {!support.hasMediaRecorder && <li>â€¢ MediaRecorder API not available</li>}
                      </ul>
                    </div>
                  )
                }
                return null
              })()}

              {/* Recording Status */}
              {recordingStatus && (
                <div className="mb-6 p-3 bg-blue-50 border border-blue-200 rounded-lg max-w-2xl mx-auto">
                  <p className="text-blue-700 text-sm">{recordingStatus}</p>
                </div>
              )}

              <div className="space-y-6">
                <Button
                  onClick={isRecording ? stopRecording : startRecording}
                  disabled={!checkMicrophoneSupport().canRecord}
                  className={`px-8 py-4 text-lg font-medium rounded-lg transition-all ${isRecording
                    ? "bg-red-600 hover:bg-red-700 text-white"
                    : "bg-purple-600 hover:bg-purple-700 text-white disabled:bg-gray-400 disabled:cursor-not-allowed"
                    }`}
                >
                  <Mic className="w-5 h-5 mr-2" />
                  {isRecording ? "Stop Recording" : "Start Recording"}
                </Button>

                {isRecording && (
                  <Card className="max-w-md mx-auto">
                    <CardContent className="p-6">
                      <div className="flex items-center justify-center space-x-2 mb-4">
                        <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse"></div>
                        <span className="text-red-700 font-medium">Recording in progress...</span>
                      </div>
                      <div className="text-2xl font-mono text-center">{formatTime(recordingTime)}</div>
                      <div className="mt-2 text-sm text-gray-600 text-center">
                        Audio will be automatically analyzed when recording stops
                      </div>
                    </CardContent>
                  </Card>
                )}

                {audioData && (
                  <Card className="max-w-md mx-auto">
                    <CardHeader>
                      <CardTitle className="text-lg">Recorded Audio</CardTitle>
                    </CardHeader>
                    <CardContent>
                      <div className="space-y-4">
                        <p className="text-sm text-gray-600">{audioData.name}</p>
                        <audio
                          ref={audioRef}
                          src={audioData.url}
                          onLoadedMetadata={(e) => {
                            const audio = e.target as HTMLAudioElement
                            if (audioData.duration === 0) {
                              setAudioData((prev) => (prev ? { ...prev, duration: Math.floor(audio.duration) } : null))
                            }
                          }}
                          onPlay={() => setIsPlaying(true)}
                          onPause={() => setIsPlaying(false)}
                          onEnded={() => setIsPlaying(false)}
                          controls
                          className="w-full"
                        />

                        {isAnalyzing && (
                          <div className="space-y-2">
                            <Progress value={analysisProgress} className="w-full" />
                            <p className="text-sm text-gray-600 text-center">Analyzing audio... {analysisProgress}%</p>
                          </div>
                        )}

                        {audioData.analysisResults && (
                          <div className="p-3 bg-green-50 border border-green-200 rounded-lg">
                            <p className="text-green-700 text-sm font-medium">âœ… Analysis Complete!</p>
                            <p className="text-green-600 text-xs mt-1">
                              Found {audioData.analysisResults.detectedSounds} sound events. Check the Analyze and Sonar
                              View tabs.
                            </p>
                          </div>
                        )}
                      </div>
                    </CardContent>
                  </Card>
                )}
              </div>
            </div>
          )}

          {activeTab === "Upload" && (
            <div className="text-center">
              <h2 className="text-2xl font-bold text-purple-600 mb-4">Upload Audio File</h2>
              <p className="text-gray-600 mb-8">Upload audio files for forensic analysis and instrument detection</p>

              <div className="max-w-2xl mx-auto">
                <label className="block">
                  <input type="file" accept="audio/*" onChange={handleFileUpload} className="hidden" />
                  <div className="border-2 border-dashed border-gray-300 rounded-lg p-12 hover:border-purple-400 transition-colors cursor-pointer">
                    <Upload className="w-12 h-12 mx-auto mb-4 text-gray-400" />
                    <p className="text-gray-500">Drag and drop audio files here or click to browse</p>
                    <p className="text-sm text-gray-400 mt-2">Supports MP3, WAV, M4A, and other audio formats</p>
                  </div>
                </label>

                {audioData && (
                  <Card className="mt-6">
                    <CardHeader>
                      <CardTitle className="text-lg">Uploaded Audio</CardTitle>
                    </CardHeader>
                    <CardContent>
                      <div className="space-y-4">
                        <p className="text-sm text-gray-600">{audioData.name}</p>
                        <audio
                          src={audioData.url}
                          controls
                          className="w-full"
                          onLoadedMetadata={(e) => {
                            const audio = e.target as HTMLAudioElement
                            setAudioData((prev) => (prev ? { ...prev, duration: Math.floor(audio.duration) } : null))
                          }}
                        />

                        {isAnalyzing && (
                          <div className="space-y-2">
                            <Progress value={analysisProgress} className="w-full" />
                            <p className="text-sm text-gray-600 text-center">Analyzing audio... {analysisProgress}%</p>
                          </div>
                        )}

                        {audioData.analysisResults && (
                          <div className="p-3 bg-green-50 border border-green-200 rounded-lg">
                            <p className="text-green-700 text-sm font-medium">âœ… Analysis Complete!</p>
                            <p className="text-green-600 text-xs mt-1">
                              Found {audioData.analysisResults.detectedSounds} sound events. Check the Analyze and Sonar
                              View tabs.
                            </p>
                          </div>
                        )}
                      </div>
                    </CardContent>
                  </Card>
                )}
              </div>
            </div>
          )}

          {activeTab === "Analyze" && <AudioAnalysis audioData={audioData} />}

          {activeTab === "Sonar View" && (
            <>
              <SonarView audioData={audioData} />
              {/* Add Live Visualization below Sonar View */}
              {audioData && audioData.analysisResults && (
                <div className="mt-8">
                  <LiveVisualization audioData={audioData} />
                </div>
              )}
            </>
          )}

          {activeTab === "About Us" && (
            <div className="max-w-4xl mx-auto">
              <h2 className="text-2xl font-bold text-purple-600 mb-6 text-center">About Audio Forensic Detector</h2>

              {/* Project Description */}
              <Card className="mb-8">
                <CardHeader>
                  <CardTitle className="text-xl text-center">Project Purpose & Description</CardTitle>
                </CardHeader>
                <CardContent className="text-center">
                  <div className="space-y-4 text-gray-700">
                    <p className="text-lg leading-relaxed">
                      The <strong>Audio Forensic Detector</strong> is an advanced web-based application designed to
                      provide comprehensive audio analysis and forensic investigation capabilities. This tool empowers
                      users to analyze audio recordings with professional-grade precision and accuracy.
                    </p>

                    <div className="grid grid-cols-1 md:grid-cols-2 gap-6 mt-6">
                      <div className="p-4 bg-purple-50 rounded-lg">
                        <h3 className="font-semibold text-purple-800 mb-2">ðŸŽ¯ Key Features</h3>
                        <ul className="text-sm text-purple-700 space-y-1 text-left">
                          <li>â€¢ Real-time audio recording and analysis</li>
                          <li>â€¢ Advanced sound event detection</li>
                          <li>â€¢ Interactive sonar-style visualization</li>
                          <li>â€¢ Frequency spectrum analysis</li>
                          <li>â€¢ Live audio processing capabilities</li>
                        </ul>
                      </div>

                      <div className="p-4 bg-blue-50 rounded-lg">
                        <h3 className="font-semibold text-blue-800 mb-2">ðŸ”¬ Applications</h3>
                        <ul className="text-sm text-blue-700 space-y-1 text-left">
                          <li>â€¢ Audio forensic investigations</li>
                          <li>â€¢ Sound quality assessment</li>
                          <li>â€¢ Voice pattern analysis</li>
                          <li>â€¢ Environmental audio monitoring</li>
                          <li>â€¢ Educational audio research</li>
                        </ul>
                      </div>
                    </div>

                    <p className="text-base mt-6 text-gray-600">
                      Built with cutting-edge web technologies, this application provides an intuitive interface for
                      both professional investigators and researchers to perform detailed audio analysis without
                      requiring specialized hardware or software installations.
                    </p>
                  </div>
                </CardContent>
              </Card>

              {/* Development Team */}
              <Card>
                <CardHeader>
                  <CardTitle className="text-xl text-center">Development Team</CardTitle>
                  <p className="text-center text-gray-600">Meet the talented developers behind this project</p>
                </CardHeader>
                <CardContent>
                  <div className="grid grid-cols-1 md:grid-cols-3 gap-6">
                    {/* Developer 1 */}
                    <div className="text-center p-6 bg-gradient-to-br from-purple-50 to-blue-50 rounded-lg border border-purple-100">
                      <div className="w-20 h-20 bg-purple-600 rounded-full mx-auto mb-4 flex items-center justify-center">
                        <span className="text-white font-bold text-xl">LC</span>
                      </div>
                      <h3 className="font-bold text-lg text-gray-800 mb-2">Lyndon Domini M. Catan</h3>
                      <p className="text-sm text-gray-600 mb-4">Lead Developer & System Architect</p>
                      <a
                        href="https://www.facebook.com/dondon.catan.359/"
                        target="_blank"
                        rel="noopener noreferrer"
                        className="inline-flex items-center px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors text-sm"
                      >
                        <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
                          <path d="M24 12.073c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.99 4.388 10.954 10.125 11.854v-8.385H7.078v-3.47h3.047V9.43c0-3.007 1.792-4.669 4.533-4.669 1.312 0 2.686.235 2.686.235v2.953H15.83c-1.491 0-1.956.925-1.956 1.874v2.25h3.328l-.532 3.47h-2.796v8.385C19.612 23.027 24 18.062 24 12.073z" />
                        </svg>
                        Facebook Profile
                      </a>
                    </div>

                    {/* Developer 2 */}
                    <div className="text-center p-6 bg-gradient-to-br from-green-50 to-teal-50 rounded-lg border border-green-100">
                      <div className="w-20 h-20 bg-green-600 rounded-full mx-auto mb-4 flex items-center justify-center">
                        <span className="text-white font-bold text-xl">KE</span>
                      </div>
                      <h3 className="font-bold text-lg text-gray-800 mb-2">Kenneth Bryan Gerabas Escala</h3>
                      <p className="text-sm text-gray-600 mb-4">Frontend Developer & UI/UX Designer</p>
                      <a
                        href="https://www.facebook.com/Kent.escala143"
                        target="_blank"
                        rel="noopener noreferrer"
                        className="inline-flex items-center px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors text-sm"
                      >
                        <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
                          <path d="M24 12.073c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.99 4.388 10.954 10.125 11.854v-8.385H7.078v-3.47h3.047V9.43c0-3.007 1.792-4.669 4.533-4.669 1.312 0 2.686.235 2.686.235v2.953H15.83c-1.491 0-1.956.925-1.956 1.874v2.25h3.328l-.532 3.47h-2.796v8.385C19.612 23.027 24 18.062 24 12.073z" />
                        </svg>
                        Facebook Profile
                      </a>
                    </div>

                    {/* Developer 3 */}
                    <div className="text-center p-6 bg-gradient-to-br from-orange-50 to-red-50 rounded-lg border border-orange-100">
                      <div className="w-20 h-20 bg-orange-600 rounded-full mx-auto mb-4 flex items-center justify-center">
                        <span className="text-white font-bold text-xl">JR</span>
                      </div>
                      <h3 className="font-bold text-lg text-gray-800 mb-2">Jairus Joshua Celis Ramos</h3>
                      <p className="text-sm text-gray-600 mb-4">Backend Developer & Audio Processing Specialist</p>
                      <a
                        href="https://www.facebook.com/jairusjoshua.ramos"
                        target="_blank"
                        rel="noopener noreferrer"
                        className="inline-flex items-center px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors text-sm"
                      >
                        <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
                          <path d="M24 12.073c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.99 4.388 10.954 10.125 11.854v-8.385H7.078v-3.47h3.047V9.43c0-3.007 1.792-4.669 4.533-4.669 1.312 0 2.686.235 2.686.235v2.953H15.83c-1.491 0-1.956.925-1.956 1.874v2.25h3.328l-.532 3.47h-2.796v8.385C19.612 23.027 24 18.062 24 12.073z" />
                        </svg>
                        Facebook Profile
                      </a>
                    </div>
                  </div>

                  {/* Team Message */}
                  <div className="mt-8 p-6 bg-gray-50 rounded-lg text-center">
                    <h4 className="font-semibold text-gray-800 mb-2">Our Mission</h4>
                    <p className="text-gray-600 text-sm leading-relaxed">
                      We are passionate about creating innovative solutions that bridge the gap between complex audio
                      analysis and user-friendly interfaces. Our goal is to make professional-grade audio forensic tools
                      accessible to everyone, from researchers and investigators to students and audio enthusiasts.
                    </p>

                    <div className="mt-4 flex justify-center space-x-4 text-xs text-gray-500">
                      <span>ðŸŽ“ Computer Science Students</span>
                      <span>â€¢</span>
                      <span>ðŸ’» Full-Stack Developers</span>
                      <span>â€¢</span>
                      <span>ðŸ”¬ Audio Technology Enthusiasts</span>
                    </div>
                  </div>

                  {/* Technology Stack */}
                  <div className="mt-6 p-4 bg-gradient-to-r from-purple-100 to-blue-100 rounded-lg">
                    <h4 className="font-semibold text-center text-gray-800 mb-3">Built With Modern Technologies</h4>
                    <div className="flex flex-wrap justify-center gap-2">
                      <Badge variant="outline" className="bg-white">
                        Next.js 14
                      </Badge>
                      <Badge variant="outline" className="bg-white">
                        React 18
                      </Badge>
                      <Badge variant="outline" className="bg-white">
                        TypeScript
                      </Badge>
                      <Badge variant="outline" className="bg-white">
                        Tailwind CSS
                      </Badge>
                      <Badge variant="outline" className="bg-white">
                        Web Audio API
                      </Badge>
                      <Badge variant="outline" className="bg-white">
                        Canvas API
                      </Badge>
                      <Badge variant="outline" className="bg-white">
                        Python (LibROSA)
                      </Badge>
                    </div>
                  </div>
                </CardContent>
              </Card>
            </div>
          )}

          {activeTab === "Settings" && <AudioSettings />}
        </div>
      </div>
    </div>
  )
}
